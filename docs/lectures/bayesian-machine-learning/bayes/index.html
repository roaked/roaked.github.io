<!doctype html><html lang=en-us dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Notes on Bayesian Inference # pip install -r requirements.txt # scipy, jax.numpy # Understanding Uncertainty via Probabilities # sum rule: P(X) = P(X,Y) + P(X, \(\neg\) Y) product rule: P(X,Y) = P(X) \(\cdot\) P(Y | X) bayes theorem on data D: \[\underbrace{P(X | D)}_{\text{posterior of X given D}} \hspace{.1cm} = { \overbrace{P(D | X)}^{\text{likelihood of X under D}} \hspace{.1cm} \cdot \hspace{.1cm} \overbrace{P(X)}^{\text{prior of X}}}{ \underbrace{P(D)}_{\text{marginalization or evidence of the model}}}\] Exponential Families # reduce Bayesian inference to:"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:title" content="Bayesian Inference"><meta property="og:description" content="Notes on Bayesian Inference # pip install -r requirements.txt # scipy, jax.numpy # Understanding Uncertainty via Probabilities # sum rule: P(X) = P(X,Y) + P(X, \(\neg\) Y) product rule: P(X,Y) = P(X) \(\cdot\) P(Y | X) bayes theorem on data D: \[\underbrace{P(X | D)}_{\text{posterior of X given D}} \hspace{.1cm} = { \overbrace{P(D | X)}^{\text{likelihood of X under D}} \hspace{.1cm} \cdot \hspace{.1cm} \overbrace{P(X)}^{\text{prior of X}}}{ \underbrace{P(D)}_{\text{marginalization or evidence of the model}}}\] Exponential Families # reduce Bayesian inference to:"><meta property="og:type" content="article"><meta property="og:url" content="https://xsleaks.dev/docs/lectures/bayesian-machine-learning/bayes/"><meta property="article:section" content="docs"><meta property="article:modified_time" content="2024-03-04T20:16:02+01:00"><title>Bayesian Inference | Ricardo Chin</title>
<link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png><link rel=stylesheet href=/book.min.b74e85bd7803de00c09a320dcf09ae0d7e37702a9918995f5fe9d1c71c55a223.css integrity="sha256-t06FvXgD3gDAmjINzwmuDX43cCqZGJlfX+nRxxxVoiM=" crossorigin=anonymous><script defer src=/sw.min.6f6f90fcb8eb1c49ec389838e6b801d0de19430b8e516902f8d75c3c8bd98739.js integrity="sha256-b2+Q/LjrHEnsOJg45rgB0N4ZQwuOUWkC+NdcPIvZhzk=" crossorigin=anonymous></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>Ricardo Chin</span></a></h2><ul><li class=book-section-flat><a href=/docs/design/>Design Repository</a><ul><li><a href=/docs/design/fea-beam-simulation/>FEA Beam Instability Modes</a><ul></ul></li><li><a href=/docs/design/industrial-crane-design/>Industrial Girder Crane</a><ul></ul></li><li><a href=/docs/design/finite-element-method-development/>FEM Package Development</a><ul></ul></li><li><a href=/docs/design/manual-transmission-design/>Gear Train Transmission</a><ul></ul></li></ul></li><li class=book-section-flat><a href=/docs/code/>System Repository</a><ul><li><a href=/docs/code/agv/>AGV: Stochastic Identification</a><ul></ul></li><li><a href=/docs/code/uav/>UAV: Red Bull Air Racing</a><ul><li><a href=/docs/code/uav/dynamics/>Drone System Dynamics</a></li><li><a href=/docs/code/uav/continuous-controller-design/>Continuous Controller</a></li><li><a href=/docs/code/uav/discrete-controller-design/>Discrete Controller</a></li><li><a href=/docs/code/uav/computer-vision/>Gate Sense: Computer Vision</a></li></ul></li><li><a href=/docs/code/robotics/>Robotics: Kin, Dynamics & Control</a><ul></ul></li><li><a href=/docs/code/deep-learning-fake-news/>Fake News: Inference & Clusters</a><ul></ul></li><li><a href=/docs/code/bin-packing/>EC Optimization: Space & Time</a><ul><li><a href=/docs/code/bin-packing/genetic-algorithm/>Genetic Algorithm</a></li><li><a href=/docs/code/bin-packing/particle-swarm-optimization/>Particle Swarm Optimization</a></li></ul></li><li><a href=/docs/code/snake-game/>Snake: Reinforcement Learning</a><ul><li><a href=/docs/code/snake-game/deepqnetwork/>Off Policy RL & Neuroevolution</a></li><li><a href=/docs/code/snake-game/adversarial/>Adversarial Multi-Agent RL</a></li></ul></li></ul></li><li class=book-section-flat><a href=/docs/competitions/>Academic Competitions</a><ul><li><a href=/docs/competitions/fst/>Formula Student Lisbon</a></li><li><a href=/docs/competitions/thermocup/>ThermoCup</a></li></ul></li><li class=book-section-flat><a href=/docs/lectures/>My Notes and Lectures</a><ul><li><a href=/docs/lectures/bayesian-machine-learning/bayes/ class=active>Bayesian Inference</a></li><li><a href=/docs/lectures/bayesian-optimization/bayesopt/>Bayesian Optimization</a></li><li><a href=/docs/lectures/hamiltonian-graphs/hamiltonian/>Fortran: Linked Lists</a></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu>
</label><strong>Bayesian Inference</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#pip-install--r-requirementstxt><strong>pip install -r requirements.txt</strong></a></li><li><a href=#scipy-jaxnumpy><strong>scipy, jax.numpy</strong></a><ul><li><a href=#understanding-uncertainty-via-probabilities><strong>Understanding Uncertainty via Probabilities</strong></a></li><li><a href=#exponential-families><strong>Exponential Families</strong></a></li></ul></li></ul></nav></aside></header><article class=markdown><h1 id=notes-on-bayesian-inference><strong>Notes on Bayesian Inference</strong>
<a class=anchor href=#notes-on-bayesian-inference>#</a></h1><h2 id=pip-install--r-requirementstxt><strong>pip install -r requirements.txt</strong>
<a class=anchor href=#pip-install--r-requirementstxt>#</a></h2><h2 id=scipy-jaxnumpy><strong>scipy, jax.numpy</strong>
<a class=anchor href=#scipy-jaxnumpy>#</a></h2><h3 id=understanding-uncertainty-via-probabilities><strong>Understanding Uncertainty via Probabilities</strong>
<a class=anchor href=#understanding-uncertainty-via-probabilities>#</a></h3><ul><li>sum rule: P(X) = P(X,Y) + P(X,
<link rel=stylesheet href=/katex/katex.min.css><script defer src=/katex/katex.min.js></script><script defer src=/katex/auto-render.min.js onload=renderMathInElement(document.body)></script><span>\(\neg\)
</span>Y)</li><li>product rule: P(X,Y) = P(X) <span>\(\cdot\)
</span>P(Y | X)</li><li>bayes theorem on data D:</li></ul><span>\[\underbrace{P(X | D)}_{\text{posterior of X given D}} \hspace{.1cm} = { \overbrace{P(D | X)}^{\text{likelihood of X under D}} \hspace{.1cm} \cdot \hspace{.1cm} \overbrace{P(X)}^{\text{prior of X}}}{ \underbrace{P(D)}_{\text{marginalization or evidence of the model}}}\]</span><h3 id=exponential-families><strong>Exponential Families</strong>
<a class=anchor href=#exponential-families>#</a></h3><ul><li><p>reduce Bayesian inference to:</p><ul><li>modelling: computing sufficient statistics <span>\(\phi(x)\)
</span>and partition function Z(w)</li><li>evaluating posterior: assessing log partition function F of the conjugate prior</li></ul></li><li><p>if F is not tractable <span>\(\Longrightarrow\)
</span>use Laplace approximations:</p><ul><li>find the mode <span>\(\^{w}\)
</span>of the posterior, by solving root-finding problems</li></ul><span>\[ \nabla_{w} log p (w | x) = \frac{\alpha + \sum_{i=1}^n \phi(x_{i})}{\nu + n}
\]</span><ul><li><p>evaluate the Hessian <span>\(\Psi = \nabla_w \nabla_w^T log p(w|x)\)
</span>at the mode <span>\(\^{w}\)</span></p></li><li><p>approximate posterior as <span>\(\mathcal{N}(w;\^{w}, --\Psi^{-1}) \)
</span>and the conjugate log partition function as:</p><span>\[ F(\alpha', \nu') \approx \sqrt{(2\pi)^d |(--\Psi^{-1})|} \cdot exp[\^{w}^T \cdot \alpha' -- log Z(^{w})^T \nu' ]
\]</span></li></ul></li></ul><blockquote class="book-hint2 important"><p class="hint-title important"><svg class="book-icon"><use href="/svg/hint-icons.svg#important-notice"/></svg><span>important</span></p>Laplace approximations reveal that Bayesian inference prioritizes capturing the geometry of the likelihood function around its peak (mode), rather than solely focusing on the prior distribution. In this context, uncertainty is better understood as encompassing the multitude of potential solutions simultaneously, rather than fixating on a single point estimate. It&rsquo;s about monitoring the breadth of plausible solutions. This means it is about observing the volume of possibilities rather than pinpointing individual points.</blockquote></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/roaked/roaked.github.io/commit/1f9b8766b95ff357f7d0e6a3729dae44e0fa8efb title='Last modified by roaked | March 4, 2024' target=_blank rel=noopener><img src=/svg/calendar.svg class=book-icon alt=Calendar>
<span>March 4, 2024</span></a></div><div><a class="flex align-center" href=https://github.com/roaked/roaked.github.io/edit/main/content/content/docs/lectures/bayesian-machine-learning/bayes.md target=_blank rel=noopener><img src=/svg/edit.svg class=book-icon alt=Edit>
<span>Ricardo Chin</span></a></div></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#pip-install--r-requirementstxt><strong>pip install -r requirements.txt</strong></a></li><li><a href=#scipy-jaxnumpy><strong>scipy, jax.numpy</strong></a><ul><li><a href=#understanding-uncertainty-via-probabilities><strong>Understanding Uncertainty via Probabilities</strong></a></li><li><a href=#exponential-families><strong>Exponential Families</strong></a></li></ul></li></ul></nav></div></aside></main></body></html>