<!doctype html><html lang=en-us dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Disco Dance of Particles # 1 Algorithm Concept # Particle Swarm Optimization (PSO) draws its inspiration from the social dynamics seen in various species, like birds and insects, as they navigate their environments to fulfill their needs. In this method, each potential solution is likened to a particle, and these particles come together to form a dynamic swarm. Each particle possesses two key characteristics: its position and its velocity. Utilizing this velocity, each particle embarks on a journey to a new position within the search space."><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:title" content="Particle Swarm Optimization"><meta property="og:description" content="Disco Dance of Particles # 1 Algorithm Concept # Particle Swarm Optimization (PSO) draws its inspiration from the social dynamics seen in various species, like birds and insects, as they navigate their environments to fulfill their needs. In this method, each potential solution is likened to a particle, and these particles come together to form a dynamic swarm. Each particle possesses two key characteristics: its position and its velocity. Utilizing this velocity, each particle embarks on a journey to a new position within the search space."><meta property="og:type" content="article"><meta property="og:url" content="https://xsleaks.dev/docs/2code/5od/_index3/"><meta property="article:section" content="docs"><meta property="article:modified_time" content="2023-11-28T20:18:26+01:00"><title>Particle Swarm Optimization | Ricardo Chin</title>
<link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png><link rel=stylesheet href=/book.min.b74e85bd7803de00c09a320dcf09ae0d7e37702a9918995f5fe9d1c71c55a223.css integrity="sha256-t06FvXgD3gDAmjINzwmuDX43cCqZGJlfX+nRxxxVoiM=" crossorigin=anonymous><script defer src=/sw.min.6f6f90fcb8eb1c49ec389838e6b801d0de19430b8e516902f8d75c3c8bd98739.js integrity="sha256-b2+Q/LjrHEnsOJg45rgB0N4ZQwuOUWkC+NdcPIvZhzk=" crossorigin=anonymous></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-10WQY47KS2"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-10WQY47KS2",{anonymize_ip:!1})}</script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>Ricardo Chin</span></a></h2><ul><li class=book-section-flat><a href=/docs/1design/>Design Portfolio</a><ul><li><a href=/docs/1design/1mest/>FEA Beam Instability Modes</a><ul></ul></li><li><a href=/docs/1design/2thermo/>ThermoCup</a><ul></ul></li><li><a href=/docs/1design/3pmec/>Industrial Crane Design</a><ul></ul></li><li><a href=/docs/1design/4mcomp/>FEM Software Development</a><ul></ul></li><li><a href=/docs/1design/5om/>Car Transmission Design</a><ul></ul></li><li><a href=/docs/1design/6ebw/>Electron Beam Technology</a><ul></ul></li><li><a href=/docs/1design/7fst/>Formula Student Lisbon</a><ul></ul></li></ul></li><li class=book-section-flat><a href=/docs/2code/>Coding Portfolio</a><ul><li><a href=/docs/2code/1drone/>UAV Red Bull Air Racing</a><ul><li><a href=/docs/2code/1drone/_index2/>Drone Dynamics</a></li><li><a href=/docs/2code/1drone/_index3/>Drone Controller Design Pt. 1</a></li><li><a href=/docs/2code/1drone/_index4/>Drone Controller Design Pt. 2</a></li><li><a href=/docs/2code/1drone/_index5/>Drone Computer Vision</a></li></ul></li><li><a href=/docs/2code/2is/>AGV: System Identification</a><ul></ul></li><li><a href=/docs/2code/3si/>Deep Learning on Fake News</a><ul></ul></li><li><a href=/docs/2code/5od/>EC Optimization: Space & Time</a><ul><li><a href=/docs/2code/5od/_index2/>Genetic Algorithm</a></li><li><a href=/docs/2code/5od/_index3/ class=active>Particle Swarm Optimization</a></li></ul></li><li><a href=/docs/2code/6au/>Sardine Factory Automation</a><ul></ul></li><li><a href=/docs/2code/7cp/hamiltonian/>Fortran: Hamiltonian Graphs</a></li><li><a href=/docs/2code/8snake/>Snake Game: Genetic RL-DQN</a><ul></ul></li><li><a href=/docs/2code/9cod/>PyBaMM-ML Battery Status</a><ul></ul></li></ul></li><li class=book-section-flat><a href=/docs/mod/>Website Modifications</a><ul></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu>
</label><strong>Particle Swarm Optimization</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#1-algorithm-concept>1 Algorithm Concept</a></li><li><a href=#2-code-implementation>2 Code Implementation</a></li><li><a href=#3-results>3 Results</a><ul><li><a href=#31-first-benchmark>3.1. First Benchmark</a></li><li><a href=#32-second-benchmark>3.2. Second Benchmark</a></li></ul></li><li><a href=#4-remarks-ga-vs-pso>4 Remarks GA vs. PSO</a></li><li><a href=#5-ending-thoughts>5 Ending Thoughts</a></li></ul></nav></aside></header><article class=markdown><h1 id=disco-dance-of-particles><strong>Disco Dance of Particles</strong>
<a class=anchor href=#disco-dance-of-particles>#</a></h1><p><img src=https://gbhat.com/assets/gifs/pso_nonconvex.gif alt=12></p><h2 id=1-algorithm-concept>1 Algorithm Concept
<a class=anchor href=#1-algorithm-concept>#</a></h2><p>Particle Swarm Optimization (PSO) draws its inspiration from the social dynamics seen in various species, like birds and insects, as they navigate their environments to fulfill their needs. In this method, each potential solution is likened to a particle, and these particles come together to form a dynamic swarm. Each particle possesses two key characteristics: its position and its velocity. Utilizing this velocity, each particle embarks on a journey to a new position within the search space. Upon arriving at these new positions, individual particle bests and the overall swarm bests are updated accordingly. The velocity of each particle is then fine-tuned based on its experiences, repeating this cycle until certain conditions are met.</p><p>Similar to <a href=https://ricardochin.com/docs/2code/5od/_index2/>Genetic Algorithm (GA)</a>, PSO commences with an initialization step wherein the initial swarm of particles is generated. The idea of representing solutions aligns closely with that of GA, where each particle begins with a random position and zero velocity. Evaluation for fitness value follows suit, where every particle&rsquo;s fitness is computed and compared against its prior best fitness and the best fitness across the entire swarm. These comparisons lead to updates in the personal bests and global bests positions. Unless a stopping criterion intervenes, the velocity and position of each particle undergo updates. These adjustments are determined by incorporating both the personal bests (pbest) and global bests (gbest) positions, along with the previous velocity, to compute the updated velocity using a defined formula.</p><p><link rel=stylesheet href=/katex/katex.min.css><script defer src=/katex/katex.min.js></script><script defer src=/katex/auto-render.min.js onload=renderMathInElement(document.body)></script><span>\[ v_{ij} = w v_{ij} + c_1 q \frac{(x_{ij}^{pb} - x_{ij})} {\Delta t} + c_2r \frac{( x_{ij}^{gb} - x_{ij})}{ \Delta t} \]
</span><span>\[ x_{ij} = x_{ij} + v_{ij} \Delta t \]</span></p><blockquote class="book-hint2 tip"><p class="hint-title tip"><svg class="book-icon"><use href="/svg/hint-icons.svg#tip-notice"/></svg><span>tip</span></p><p>The variables are:</p><ul><li>w: Inertia weight</li><li>c1: Represents the experience of an individual particle (cognitive or self learning factor)</li><li>c2: Represents the experience of the whole swarm (group or social learning factor)</li><li>r and q: Random variables from 0 to 1</li><li>wij: Diversification term &ndash; responsible for searching for new solutions in new regions while the rest of the expression is the intensification term, which explores the current region with the objective of finding a better solution</li></ul></blockquote><p>The velocity is also limited by upper and lower bounds (maximum and minimum velocities), since if the velocity is too high, the algorithm may become too unstable. In addition, a noteworthy aspect of the PSO algorithm is its divergence from the necessity of sorting fitness values of solutions throughout its processes. This particular characteristic could serve as a considerable computational advantage, particularly in scenarios where dealing with a large population size. Unlike GA, which often involves sorting operations, PSO relies on straightforward arithmetic operations involving real numbers for its velocity and position updates. This simplicity in operations contributes to its efficiency, making it an appealing choice, especially in computational-intensive situations.</p><h2 id=2-code-implementation>2 Code Implementation
<a class=anchor href=#2-code-implementation>#</a></h2><blockquote class="book-hint2 example"><p class="hint-title example"><svg class="book-icon"><use href="/svg/hint-icons.svg#example-notice"/></svg><span>example</span></p>A similar approach for the code implementation was used for the <a href=https://ricardochin.com/docs/2code/5od/_index2/>Genetic Algorithm. If you want to read more about it as an example, click here.</a>. Hence, I will ommit duplicate writing.</blockquote><h2 id=3-results>3 Results
<a class=anchor href=#3-results>#</a></h2><h3 id=31-first-benchmark>3.1. First Benchmark
<a class=anchor href=#31-first-benchmark>#</a></h3><p>For the initial benchmark, PSO underwent 10 simulations, each employing the following set of parameters:</p><p><img src=https://live.staticflickr.com/65535/53360419499_f1b24207df.jpg alt=1></p><p><img src=https://live.staticflickr.com/65535/53360419489_89b9888fff_c.jpg alt=2></p><p>It was evident that while PSO demonstrated notable advantages over GA, showcasing rapid convergence in specific scenarios, it also revealed certain limitations. These included susceptibility to getting trapped in local optima and a significant decline in convergence rate, as evidenced by all (10) simulations becoming non-feasible upon reaching the stopping criteria. Attempts to bolster PSO&rsquo;s performance through parameter tuning yielded limited success.</p><p>In response to these challenges, an innovative approach was adopted by introducing a mutation mechanism. This involved mutations affecting both the particles&rsquo; personal best and the global best. Integrating this mutation operator into the PSO algorithm offered significant benefits. Not only did it expedite convergence, but it also mitigated premature convergence issues, thereby enhancing accuracy and circumventing the aforementioned challenges.</p><p>Multiple experiments were conducted in an effort to fine-tune the diverse parameters. The initial focus was on understanding the influence of population size. Interestingly, it was noted that augmenting the population had only a restrained impact on the number of optimal solutions, particularly when the number of iterations remained unchanged. The experiments were executed using the following parameters: w = 0.9, wdamp = 0.99, c1 = c2 = 2, VelMax = 0.0001, nParticleMutation = 3, and nGlobalBestMutation = 10.</p><table><thead><tr><th>Population Size</th><th>Optimal Sols</th><th>Non-Optimal Sols</th><th>Non-feasible</th><th>Average Simulation Time (s)</th></tr></thead><tbody><tr><td>10</td><td>18</td><td>2</td><td>0</td><td>7.6248</td></tr><tr><td>20</td><td>19</td><td>1</td><td>0</td><td>12.5746</td></tr><tr><td>50</td><td>15</td><td>5</td><td>0</td><td>29.8416</td></tr></tbody></table><p>20 simulations were conducted for each scenario, solely manipulating the population size. The results indicate a correlation wherein augmenting the population size enhances the model&rsquo;s performance while concurrently elongating the simulation time. Optimal performance was observed when the population size was set at 20. Among the 20 simulations, the algorithm remarkably attained the global optimal solution in 19 instances, narrowly missing it in just one simulation. Notably, no non-feasible solutions were encountered, which stands as a significant advantage over the GA.</p><p>The subsequent step aimed to discern the impact of particle mutation and global best mutation on our model&rsquo;s performance. To ensure more conclusive outcomes, a total of 100 simulations were executed for each scenario:</p><table><thead><tr><th>Particle Mutation</th><th>GB Mutation</th><th>Optimal Sols</th><th>Non-Optimal Sols</th><th>AVG Time (s)</th><th>Best Time (s)</th></tr></thead><tbody><tr><td>3</td><td>20</td><td>100</td><td>0</td><td>5.7910</td><td>2.4609</td></tr><tr><td>5</td><td>20</td><td>100</td><td>0</td><td>7.7046</td><td>3.7946</td></tr><tr><td>3</td><td>10</td><td>92</td><td>8</td><td>12.5384</td><td>2.8647</td></tr><tr><td>1</td><td>20</td><td>92</td><td>8</td><td>4.0097</td><td>1.6442</td></tr><tr><td>1</td><td>10</td><td>88</td><td>12</td><td>6.8914</td><td>1.5468</td></tr><tr><td>1</td><td>5</td><td>87</td><td>12</td><td>10.7145</td><td>1.8855</td></tr><tr><td>10</td><td>3</td><td>82</td><td>18</td><td>85.6950</td><td>15.5693</td></tr><tr><td>1</td><td>3</td><td>82</td><td>18</td><td>14.3089</td><td>2.1009</td></tr></tbody></table><p>The initial tests were conducted with a population size of 20, revealing notably extended average simulation times in certain experiments. Consequently, to expedite the process, the population size was adjusted to 10:</p><table><thead><tr><th>Particle Mutation</th><th>GB Mutation</th><th>Optimal Sols</th><th>Non-Optimal Sols</th><th>AVG Time (s)</th><th>Best Time (s)</th></tr></thead><tbody><tr><td>3</td><td>20</td><td>100</td><td>0</td><td>3.7797</td><td>1.5666</td></tr><tr><td>5</td><td>20</td><td>100</td><td>0</td><td>4.1108</td><td>2.1950</td></tr><tr><td>3</td><td>15</td><td>94</td><td>6</td><td>5.9879</td><td>1.7073</td></tr><tr><td>3</td><td>10</td><td>86</td><td>14</td><td>6.7412</td><td>1.4942</td></tr><tr><td>3</td><td>3</td><td>72</td><td>14</td><td>15.2054</td><td>2.1753</td></tr></tbody></table><p>Increasing the count of global best mutations while reducing the number of particle mutations notably enhanced overall performance. When employing either 3 or 5 particle mutations alongside 20 global best mutations, all simulations resulted in achieving the optimal solution — an outstanding outcome for PSO. The preference leans towards 3 particle mutations due to its lower simulation times, presenting a favourable trade-off.</p><p>Moreover, these parameters wield a direct influence on average simulation time. Fewer mutation values expedite each iteration but risk resembling the original PSO, increasing the chances of entrapment and necessitating more iterations, ultimately leading to non-feasible solutions and elongated simulation times. Conversely, an excess of mutations doesn&rsquo;t significantly benefit performance. Based on the data, the optimal parameters thus far appear to be nPop = 10, nParticleMutation = 3, and nGlobalBestMutation = 20.</p><p>Further evaluations explored the impact of maximum velocity on the algorithm. Tests were conducted at different velocities while maintaining other parameters constant.</p><p><img src=https://live.staticflickr.com/65535/53360310213_90bfabcdbc_c.jpg alt=213></p><p>The examination reveals that higher velocities introduce instability to the algorithm, manifesting as noise in the Average Cost plot. Notably, a MaxVel of 0.01 resulted in an Average Cost oscillating around 18, while reducing MaxVel to 0.001 led to oscillations closer to 16. This velocity variation also impacted the Best Cost of the particles; higher velocities correlated with higher Best Cost. This sensitivity of the algorithm to velocity proves crucial when tackling the bin packing problem.</p><p>In addition to velocity, the parameters related to inertia (w and wdamp) and learning factors (c1 and c2) underwent testing. To comprehend their impacts better, mutations were maintained at lower values. If set too low, the algorithm would require more iterations to find the optimal solution due to excessively low velocities, thereby affecting simulation time. Conversely, excessively high values would cause velocities to saturate quickly to the maximum allowed value, which is also suboptimal. However, unlike mutations, these parameters didn&rsquo;t exhibit the same influential impact. Ultimately, values were selected based on recommendations found in literature, settling on c1 = c2 = 2, w = 0.9, and wdamp = 0.99.</p><p>Afterwards, the PSO algorithm underwent testing utilizing the following parameters: nPop = 10, w = 0.9, wdamp = 0.99, c1 = c2 = 2, VelMax = 0.0001, nParticleMutation = 3, and nGlobalBestMutation = 20:</p><p><img src=https://live.staticflickr.com/65535/53359214432_4fd4ff5172.jpg alt=123></p><p>Next, convergence for best cost (left) and average cost (right) over the iterations was depicted:</p><p><img src=https://live.staticflickr.com/65535/53360310203_29792b6c15_b.jpg alt=1241f></p><p>In this simulation, the PSO algorithm completed 206 iterations within 2.52 seconds before reaching its stopping criteria. Remarkably, it displayed rapid convergence for this specific benchmark. The average cost of the particles notably decreased to 15.8 before the simulation concluded. Typically, this value fluctuates between 15 and 16 with a higher number of iterations.</p><h3 id=32-second-benchmark>3.2. Second Benchmark
<a class=anchor href=#32-second-benchmark>#</a></h3><p>In the second benchmark, the PSO underwent testing using identical parameters to those employed in the first benchmark: nPop = 10, w = 0.9, wdamp = 0.99, c1 = c2 = 2, VelMax = 0.0001, nParticleMutation = 3, and nGlobalBestMutation = 20.</p><p>While the algorithm doesn&rsquo;t yield identical results in each simulation, it managed to attain the optimal solution in certain instances. Here is the outcome of one such simulation depicted:</p><p><img src=https://live.staticflickr.com/65535/53359214352_f9a2bceea8.jpg alt=asfvcc2></p><p><img src=https://live.staticflickr.com/65535/53360419374_79b7e25865_c.jpg alt=asdad></p><p>In this particular simulation, the PSO algorithm required 8895 iterations, spanning 444.18 seconds, before meeting the stopping criteria. The algorithm showcased rapid convergence initially, achieving a cost of less than 101 within 1000 iterations. However, it encountered challenges reaching the optimal solution, nearly getting stuck at certain points, evident in the best cost plot. Throughout the process, the average cost of the particles fluctuated between 105 and 107.</p><h2 id=4-remarks-ga-vs-pso>4 Remarks GA vs. PSO
<a class=anchor href=#4-remarks-ga-vs-pso>#</a></h2><blockquote class="book-hint2 tip"><p class="hint-title tip"><svg class="book-icon"><use href="/svg/hint-icons.svg#tip-notice"/></svg><span>tip</span></p><a href=https://ricardochin.com/docs/2code/5od/_index3/>If you would like to return to advance to the implementation using particle swarm optimization click here ✌️</a></blockquote><p>To further test and compare the GA and PSO algorithms, they were ran 10 times each with the second benchmark.</p><p><img src=https://live.staticflickr.com/65535/53359214342_fb24701070_c.jpg alt=sadsad></p><p><img src=https://live.staticflickr.com/65535/53360549430_e11ea23c48_c.jpg alt=das></p><p>In one set of trials, the algorithm achieved 102 bins once and 4 times in total. However, it successfully obtained feasible solutions in 7 out of 10 attempts. The average time across these 10 simulations stood at 284.40 seconds (averaging 6402 iterations). The most efficient solution, involving 101 bins, was attained in 237.06 seconds (5583 iterations).</p><p>Conversely, the PSO algorithm hit the optimal solution only 3 times in 10 simulations, which is less than ideal. Nonetheless, it managed to secure feasible solutions in 9 out of these 10 instances. Notably, the algorithm failed to obtain a feasible solution only when attempting to accommodate all items within 99 bins—an impossible feat. The average time for these 10 simulations totaled 149.37 seconds (averaging 3160 iterations). The best time among the 3 optimal solutions was 107.84 seconds (2303 iterations). Interestingly, three out of the first five simulations resulted in optimal solutions.</p><p>Comparatively, both algorithms encountered a higher percentage of non-feasible solutions in the second benchmark compared to the first. This discrepancy aligns with expectations, given the increased complexity of the second benchmark.</p><h2 id=5-ending-thoughts>5 Ending Thoughts
<a class=anchor href=#5-ending-thoughts>#</a></h2><p><a href=https://ricardochin.com/docs/2code/5od/#5-ending-thoughts>I have included a brief summary about the algorithms in the main chapter, kindly click here!</a></p></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/roaked/roaked.github.io/commit/d251a20bc6cebd95f5f7793abfb7478aee68639a title='Last modified by roaked | November 28, 2023' target=_blank rel=noopener><img src=/svg/calendar.svg class=book-icon alt=Calendar>
<span>November 28, 2023</span></a></div><div><a class="flex align-center" href=https://github.com/roaked/roaked.github.io/edit/main/content/content/docs/2code/5od/_index3.md target=_blank rel=noopener><img src=/svg/edit.svg class=book-icon alt=Edit>
<span>Ricardo Chin</span></a></div></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#1-algorithm-concept>1 Algorithm Concept</a></li><li><a href=#2-code-implementation>2 Code Implementation</a></li><li><a href=#3-results>3 Results</a><ul><li><a href=#31-first-benchmark>3.1. First Benchmark</a></li><li><a href=#32-second-benchmark>3.2. Second Benchmark</a></li></ul></li><li><a href=#4-remarks-ga-vs-pso>4 Remarks GA vs. PSO</a></li><li><a href=#5-ending-thoughts>5 Ending Thoughts</a></li></ul></nav></div></aside></main></body></html>