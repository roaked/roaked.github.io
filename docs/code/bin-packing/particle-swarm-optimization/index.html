<!doctype html><html lang=en-us dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Disco Dance of Particles # 1 Algorithm Concept # Particle Swarm Optimization (PSO) draws its inspiration from the social dynamics seen in various species, like birds and insects, as they navigate their environments to fulfill their needs. In this method, each potential solution is likened to a particle, and these particles come together to form a dynamic swarm. Each particle possesses two key characteristics: its position and its velocity. Utilizing this velocity, each particle embarks on a journey to a new position within the search space."><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:title" content="Particle Swarm Optimization"><meta property="og:description" content="Disco Dance of Particles # 1 Algorithm Concept # Particle Swarm Optimization (PSO) draws its inspiration from the social dynamics seen in various species, like birds and insects, as they navigate their environments to fulfill their needs. In this method, each potential solution is likened to a particle, and these particles come together to form a dynamic swarm. Each particle possesses two key characteristics: its position and its velocity. Utilizing this velocity, each particle embarks on a journey to a new position within the search space."><meta property="og:type" content="article"><meta property="og:url" content="https://xsleaks.dev/docs/code/bin-packing/particle-swarm-optimization/"><meta property="article:section" content="docs"><meta property="article:modified_time" content="2024-02-16T14:19:31+01:00"><title>Particle Swarm Optimization | Ricardo Chin</title>
<link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png><link rel=stylesheet href=/book.min.b74e85bd7803de00c09a320dcf09ae0d7e37702a9918995f5fe9d1c71c55a223.css integrity="sha256-t06FvXgD3gDAmjINzwmuDX43cCqZGJlfX+nRxxxVoiM=" crossorigin=anonymous><script defer src=/sw.min.6f6f90fcb8eb1c49ec389838e6b801d0de19430b8e516902f8d75c3c8bd98739.js integrity="sha256-b2+Q/LjrHEnsOJg45rgB0N4ZQwuOUWkC+NdcPIvZhzk=" crossorigin=anonymous></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>Ricardo Chin</span></a></h2><ul><li class=book-section-flat><a href=/docs/design/>Design Repository</a><ul><li><a href=/docs/design/fea-beam-simulation/>FEA Beam Instability Modes</a><ul></ul></li><li><a href=/docs/design/industrial-crane-design/>Industrial Girder Crane</a><ul></ul></li><li><a href=/docs/design/finite-element-method-development/>FEM Package Development</a><ul></ul></li><li><a href=/docs/design/manual-transmission-design/>Gear Train Transmission</a><ul></ul></li><li><a href=/docs/design/electron-beam-tech/>Electron Beam Technology</a><ul></ul></li></ul></li><li class=book-section-flat><a href=/docs/code/>System Repository</a><ul><li><a href=/docs/code/agv/>AGV: Stochastic Identification</a><ul></ul></li><li><a href=/docs/code/uav/>UAV: Red Bull Air Racing</a><ul><li><a href=/docs/code/uav/dynamics/>Drone System Dynamics</a></li><li><a href=/docs/code/uav/continuous-controller-design/>Continuous Controller</a></li><li><a href=/docs/code/uav/discrete-controller-design/>Discrete Controller</a></li><li><a href=/docs/code/uav/computer-vision/>Gate Sense: Computer Vision</a></li></ul></li><li><a href=/docs/code/robotics/>Robotics: Kin, Dynamics & Control</a><ul></ul></li><li><a href=/docs/code/deep-learning-fake-news/>Fake News: Clusters, FIS & ANN</a><ul></ul></li><li><a href=/docs/code/bin-packing/>EC Optimization: Space & Time</a><ul><li><a href=/docs/code/bin-packing/genetic-algorithm/>Genetic Algorithm</a></li><li><a href=/docs/code/bin-packing/particle-swarm-optimization/ class=active>Particle Swarm Optimization</a></li></ul></li><li><a href=/docs/code/snake-game/>Snake Game: Reinforcement Learning</a><ul></ul></li><li><a href=/docs/code/micromouse/>Micromouse: Flood Fill to A*</a><ul></ul></li></ul></li><li class=book-section-flat><a href=/docs/competitions/>Academic Competitions</a><ul><li><a href=/docs/competitions/fst/>Formula Student Lisbon</a></li><li><a href=/docs/competitions/thermocup/>ThermoCup</a></li></ul></li><li class=book-section-flat><a href=/docs/lectures/>My Programming Lectures</a><ul><li><a href=/docs/lectures/hamiltonian-graphs/hamiltonian/>Hamiltonian Paths: Linked Lists</a></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu>
</label><strong>Particle Swarm Optimization</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#1-algorithm-concept>1 Algorithm Concept</a></li><li><a href=#2-code-implementation>2 Code Implementation</a></li><li><a href=#3-results>3 Results</a><ul><li><a href=#31-first-benchmark>3.1. First Benchmark</a></li><li><a href=#32-second-benchmark>3.2. Second Benchmark</a></li></ul></li><li><a href=#4-remarks-ga-vs-pso>4 Remarks GA vs. PSO</a></li><li><a href=#5-ending-thoughts>5 Ending Thoughts</a></li></ul></nav></aside></header><article class=markdown><h1 id=disco-dance-of-particles><strong>Disco Dance of Particles</strong>
<a class=anchor href=#disco-dance-of-particles>#</a></h1><p><img src=https://gbhat.com/assets/gifs/pso_nonconvex.gif alt=12></p><h2 id=1-algorithm-concept>1 Algorithm Concept
<a class=anchor href=#1-algorithm-concept>#</a></h2><p>Particle Swarm Optimization (PSO) draws its inspiration from the social dynamics seen in various species, like birds and insects, as they navigate their environments to fulfill their needs. In this method, each potential solution is likened to a particle, and these particles come together to form a dynamic swarm. Each particle possesses two key characteristics: its position and its velocity. Utilizing this velocity, each particle embarks on a journey to a new position within the search space. Upon arriving at these new positions, individual particle bests and the overall swarm bests are updated accordingly. The velocity of each particle is then fine-tuned based on its experiences, repeating this cycle until certain conditions are met.</p><p>Similar to <a href=https://ricardochin.com/docs/code/bin-packing/genetic-algorithm/>Genetic Algorithm (GA)</a>, PSO commences with an initialization step wherein the initial swarm of particles is generated. The idea of representing solutions aligns closely with that of GA, where each particle begins with a random position and zero velocity.</p><p>Evaluation for fitness value follows, where every particle&rsquo;s fitness is computed and compared against its prior best fitness and the best fitness across the entire swarm. These comparisons lead to updates in the personal bests and global bests positions. Unless a stopping criterion intervenes, the velocity and position of each particle undergo updates. These adjustments are determined by incorporating both the personal bests (<code>pbest</code>) and global bests (<code>gbest</code>) positions, along with the previous velocity, to compute the updated velocity using a defined formula.</p><p><link rel=stylesheet href=/katex/katex.min.css><script defer src=/katex/katex.min.js></script><script defer src=/katex/auto-render.min.js onload=renderMathInElement(document.body)></script><span>\[ v_{ij} = w v_{ij} + c_1 q \frac{(x_{ij}^{pb} - x_{ij})} {\Delta t} + c_2r \frac{( x_{ij}^{gb} - x_{ij})}{ \Delta t} \]
</span><span>\[ x_{ij} = x_{ij} + v_{ij} \Delta t \]</span></p><blockquote class="book-hint2 note"><p class="hint-title note"><svg class="book-icon"><use href="/svg/hint-icons.svg#note-notice"/></svg><span>note</span></p><p>The variables are:</p><ul><li>w: Inertia weight</li><li>c1: Represents the experience of an individual particle (cognitive or self learning factor)</li><li>c2: Represents the experience of the whole swarm (group or social learning factor)</li><li>r and q: Random variables from 0 to 1</li><li>vwij: This is the <strong>diversification term</strong> which is responsible for searching for new solutions in new regions while the rest of the expression is the <strong>intensification term</strong>, which explores the current region with the objective of finding a better solution</li></ul></blockquote><p>The velocity is also limited by upper and lower bounds (maximum and minimum velocities), since if the velocity is too high, the algorithm may become too unstable. In addition, a noteworthy aspect of the PSO algorithm is its divergence from the necessity of sorting fitness values of solutions throughout its processes. This particular characteristic could serve as a considerable computational advantage, particularly in scenarios where dealing with a large population size. Unlike GA, which often involves sorting operations, PSO relies on straightforward arithmetic operations involving real numbers for its velocity and position updates. This simplicity in operations contributes to its efficiency, making it an appealing choice, especially in computational-intensive situations.</p><h2 id=2-code-implementation>2 Code Implementation
<a class=anchor href=#2-code-implementation>#</a></h2><blockquote class="book-hint2 important"><p class="hint-title important"><svg class="book-icon"><use href="/svg/hint-icons.svg#important-notice"/></svg><span>important</span></p>A similar approach for the code implementation was used for the <a href=https://ricardochin.com/docs/code/bin-packing/genetic-algorithm/>GA</a></blockquote><p>The implementation presented through the function <code>PSO.m</code> initializes parameters, including the objective function <code>CostFunction</code> and defines variables related to the problem, such as the number of decision variables <code>nVar</code>, their boundaries <code>VarMin</code> and <code>VarMax</code>, and PSO-specific parameters like maximum iterations <code>MaxIt</code>, population size <code>nPop</code>, and velocity limits.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-matlab data-lang=matlab><span style=display:flex><span>nVar = <span style=color:#ae81ff>2</span><span style=color:#f92672>*</span>model.n<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>;     <span style=color:#75715e>% Number of Decision Variables</span>
</span></span><span style=display:flex><span>VarSize = [<span style=color:#ae81ff>1</span> nVar];     <span style=color:#75715e>% Decision Variables Matrix Size</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>VarMin = <span style=color:#ae81ff>0</span>;        <span style=color:#75715e>% Lower Bound of Decision Variables</span>
</span></span><span style=display:flex><span>VarMax = nVar;     <span style=color:#75715e>% Upper Bound of Decision Variables</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>%% PSO Parameters</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> model.n <span style=color:#f92672>&lt;</span> <span style=color:#ae81ff>100</span>
</span></span><span style=display:flex><span>    MaxIt = <span style=color:#ae81ff>3000</span>;            <span style=color:#75715e>% Maximum Number of Iterations</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>else</span>
</span></span><span style=display:flex><span>    MaxIt = <span style=color:#ae81ff>30000</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>end</span>
</span></span></code></pre></div><p>The script initializes the particles (potential solutions) and their velocities randomly within defined bounds. It evaluates the cost of each particle based on the provided objective function <code>CostFunction</code>. This cost function is depicted in <code>PSO_BinPackingCost.m</code>, it assesses the cost of a bin packing solution based on input parameters <code>x</code> and <code>model</code>.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-matlab data-lang=matlab><span style=display:flex><span>empty_particle.Position = [];
</span></span><span style=display:flex><span>empty_particle.Cost = [];
</span></span><span style=display:flex><span>empty_particle.Sol = [];
</span></span><span style=display:flex><span>empty_particle.Velocity = [];
</span></span><span style=display:flex><span>empty_particle.Best.Position = [];
</span></span><span style=display:flex><span><span style=color:#75715e>%... other empty_particle fields</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>particle = repmat(empty_particle, nPop, <span style=color:#ae81ff>1</span>);
</span></span><span style=display:flex><span>GlobalBest.Cost = inf;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> i = <span style=color:#ae81ff>1</span>:nPop
</span></span><span style=display:flex><span>    particle(i).Position = unifrnd(VarMin, VarMax, VarSize);
</span></span><span style=display:flex><span>    particle(i).Velocity = zeros(VarSize);
</span></span><span style=display:flex><span>    <span style=color:#75715e>%... evaluation and updating best positions</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>end</span>
</span></span><span style=display:flex><span><span style=color:#75715e>%... BestCost and AvgCost initialization</span>
</span></span></code></pre></div><p>Afterwards, the main <code>PSO.m</code> function iterates through a predefined number of iterations <code>MaxIt</code>, wherein each iteration involves updating the velocities of particles based on personal and global best positions. It subsequently adjusts particle positions considering the updated velocities and ensures these positions adhere to predefined limits. Within each iteration, the loop evaluates the cost of each particle&rsquo;s position using the provided objective function, <a href=https://github.com/roaked/genetic-algorithm-optimization/blob/main/bpp/PSO_Mutate.m>applies mutation operations</a> to potentially enhance solutions, and updates personal best positions accordingly. Additionally, the algorithm tracks the global best solution among all particles. Throughout iterations, it collects information about the best solution found <code>BestSol</code>, its associated cost <code>BestCost</code>, the average cost <code>AvgCost</code>, and displays the progress.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-matlab data-lang=matlab><span style=display:flex><span>    <span style=color:#66d9ef>for</span> it = <span style=color:#ae81ff>1</span>:MaxIt
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> i = <span style=color:#ae81ff>1</span>:nPop
</span></span><span style=display:flex><span>            <span style=color:#75715e>% Update velocity</span>
</span></span><span style=display:flex><span>            particle(i).Velocity = w <span style=color:#f92672>*</span> particle(i).Velocity <span style=color:#75715e>...</span>
</span></span><span style=display:flex><span>                <span style=color:#f92672>+</span> c1 <span style=color:#f92672>*</span> rand(VarSize) <span style=color:#f92672>.*</span> (particle(i).Best.Position <span style=color:#f92672>-</span> particle(i).Position) <span style=color:#75715e>...</span>
</span></span><span style=display:flex><span>                <span style=color:#f92672>+</span> c2 <span style=color:#f92672>*</span> rand(VarSize) <span style=color:#f92672>.*</span> (GlobalBest.Position <span style=color:#f92672>-</span> particle(i).Position);
</span></span><span style=display:flex><span>            <span style=color:#75715e>%... velocity and position adjustments</span>
</span></span><span style=display:flex><span>            <span style=color:#75715e>%... cost evaluation and mutation operations</span>
</span></span><span style=display:flex><span>            <span style=color:#75715e>%... updating personal and global best</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>end</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e>%... adjusting parameters and collecting data for BestSol, BestCost, and AvgCost</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e>%... breaking criteria based on the stuckCounter</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>end</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>%... end of the PSO loop, returning results</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>end</span>
</span></span></code></pre></div><p>As shown above, the loop includes a stopping criterion based on a stuck counter to break out if the algorithm appears trapped in a solution or reaches the maximum number of iterations. Upon completion or reaching the stopping criteria, the loop returns the gathered results.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-matlab data-lang=matlab><span style=display:flex><span><span style=color:#66d9ef>if</span> (it<span style=color:#f92672>&gt;</span>=<span style=color:#ae81ff>50</span>)  
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> (BestCost(it,<span style=color:#ae81ff>1</span>) <span style=color:#f92672>==</span> BestCost(it<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>1</span>)) <span style=color:#f92672>&amp;&amp;</span> BestCost(it,<span style=color:#ae81ff>1</span>) <span style=color:#f92672>==</span> floor(BestCost(it,<span style=color:#ae81ff>1</span>))
</span></span><span style=display:flex><span>            <span style=color:#75715e>%Stuck in feasible solution</span>
</span></span><span style=display:flex><span>            stuckCounter=stuckCounter<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span>;
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> (stuckCounter <span style=color:#f92672>==</span> <span style=color:#ae81ff>100</span>)
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>break</span>;        
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>end</span>
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>elseif</span> (BestCost(it,<span style=color:#ae81ff>1</span>) <span style=color:#f92672>==</span> BestCost(it<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>1</span>))
</span></span><span style=display:flex><span>            <span style=color:#75715e>%Stuck in unfeasible solution</span>
</span></span><span style=display:flex><span>            stuckCounter=stuckCounter<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span>;
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> (stuckCounter <span style=color:#f92672>==</span> <span style=color:#ae81ff>5000</span>)
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>break</span>;        
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>end</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>else</span> 
</span></span><span style=display:flex><span>            stuckCounter=<span style=color:#ae81ff>1</span>;   
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>end</span>
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>end</span>
</span></span></code></pre></div><h2 id=3-results>3 Results
<a class=anchor href=#3-results>#</a></h2><h3 id=31-first-benchmark>3.1. First Benchmark
<a class=anchor href=#31-first-benchmark>#</a></h3><p>For the initial benchmark, PSO underwent 10 simulations, each employing the following set of parameters:</p><p><img src=https://live.staticflickr.com/65535/53360419499_f1b24207df.jpg alt=1></p><p><img src=https://live.staticflickr.com/65535/53360419489_89b9888fff_c.jpg alt=2></p><p>It was evident that while PSO demonstrated notable advantages over GA, showcasing rapid convergence in specific scenarios, it also revealed certain limitations. These included susceptibility to getting trapped in local optima and a significant decline in convergence rate, as evidenced by all (10) simulations becoming non-feasible upon reaching the stopping criteria. Attempts to boost PSO&rsquo;s performance through parameter tuning yielded limited success.</p><p>In response to these challenges, an innovative approach was adopted by introducing a mutation mechanism. This involved mutations affecting both the particles&rsquo; personal best and the global best. Integrating this mutation operator into the PSO algorithm offered significant benefits. Not only did it expedite convergence, but it also mitigated premature convergence issues, thereby enhancing accuracy and circumventing the aforementioned challenges.</p><p>Multiple experiments were conducted in an effort to fine-tune the diverse parameters. The initial focus was on understanding the influence of population size. Interestingly, it was noted that augmenting the population had only a restrained impact on the number of optimal solutions, particularly when the number of iterations remained unchanged. The experiments were executed using the following parameters: <code>w = 0.9</code>, <code>wdamp = 0.99</code>, <code>c1 = c2 = 2</code>, <code>VelMax = 0.0001</code>, <code>nParticleMutation = 3</code> and <code>nGlobalBestMutation = 10</code>.</p><table><thead><tr><th>Population Size</th><th>Optimal Sols</th><th>Non-Optimal Sols</th><th>Non-feasible</th><th>Average Simulation Time (s)</th></tr></thead><tbody><tr><td>10</td><td>18</td><td>2</td><td>0</td><td>7.6248</td></tr><tr><td>20</td><td>19</td><td>1</td><td>0</td><td>12.5746</td></tr><tr><td>50</td><td>15</td><td>5</td><td>0</td><td>29.8416</td></tr></tbody></table><p>20 simulations were conducted for each scenario, solely manipulating the population size. The results indicate a correlation wherein augmenting the population size enhances the model&rsquo;s performance while concurrently elongating the simulation time. Optimal performance was observed when the population size was set at 20. Among the 20 simulations, the algorithm remarkably attained the global optimal solution in 19 instances, narrowly missing it in just one simulation. Notably, no non-feasible solutions were encountered, which stands as a significant advantage over the GA.</p><p>The subsequent step aimed to discern the impact of particle mutation and global best mutation on our model&rsquo;s performance. To ensure more conclusive outcomes, a total of 100 simulations were executed for each scenario:</p><table><thead><tr><th>Particle Mutation</th><th>GB Mutation</th><th>Optimal Sols</th><th>Non-Optimal Sols</th><th>AVG Time (s)</th><th>Best Time (s)</th></tr></thead><tbody><tr><td>3</td><td>20</td><td>100</td><td>0</td><td>5.7910</td><td>2.4609</td></tr><tr><td>5</td><td>20</td><td>100</td><td>0</td><td>7.7046</td><td>3.7946</td></tr><tr><td>3</td><td>10</td><td>92</td><td>8</td><td>12.5384</td><td>2.8647</td></tr><tr><td>1</td><td>20</td><td>92</td><td>8</td><td>4.0097</td><td>1.6442</td></tr><tr><td>1</td><td>10</td><td>88</td><td>12</td><td>6.8914</td><td>1.5468</td></tr><tr><td>1</td><td>5</td><td>87</td><td>12</td><td>10.7145</td><td>1.8855</td></tr><tr><td>10</td><td>3</td><td>82</td><td>18</td><td>85.6950</td><td>15.5693</td></tr><tr><td>1</td><td>3</td><td>82</td><td>18</td><td>14.3089</td><td>2.1009</td></tr></tbody></table><p>The initial tests were conducted with a population size of 20, revealing notably extended average simulation times in certain experiments. Consequently, to expedite the process, the population size was adjusted to 10:</p><table><thead><tr><th>Particle Mutation</th><th>GB Mutation</th><th>Optimal Sols</th><th>Non-Optimal Sols</th><th>AVG Time (s)</th><th>Best Time (s)</th></tr></thead><tbody><tr><td>3</td><td>20</td><td>100</td><td>0</td><td>3.7797</td><td>1.5666</td></tr><tr><td>5</td><td>20</td><td>100</td><td>0</td><td>4.1108</td><td>2.1950</td></tr><tr><td>3</td><td>15</td><td>94</td><td>6</td><td>5.9879</td><td>1.7073</td></tr><tr><td>3</td><td>10</td><td>86</td><td>14</td><td>6.7412</td><td>1.4942</td></tr><tr><td>3</td><td>3</td><td>72</td><td>14</td><td>15.2054</td><td>2.1753</td></tr></tbody></table><p>Increasing the count of global best mutations while reducing the number of particle mutations notably enhanced overall performance. When employing either 3 or 5 particle mutations alongside 20 global best mutations, all simulations resulted in achieving the optimal solution — an outstanding outcome for PSO. The preference leans towards 3 particle mutations due to its lower simulation times, presenting a favourable trade-off.</p><p>Moreover, these parameters wield a direct influence on average simulation time. Fewer mutation values expedite each iteration but risk resembling the original PSO, increasing the chances of entrapment and necessitating more iterations, ultimately leading to non-feasible solutions and elongated simulation times. Conversely, an excess of mutations doesn&rsquo;t significantly benefit performance. Based on the data, the optimal parameters thus far appear to be <code>nPop = 10</code>, <code>nParticleMutation = 3</code> and <code>nGlobalBestMutation = 20</code>.</p><p>Further evaluations explored the impact of maximum velocity on the algorithm. Tests were conducted at different velocities while maintaining other parameters constant.</p><p><img src=https://live.staticflickr.com/65535/53360310213_90bfabcdbc_c.jpg alt=213></p><p>The examination reveals that higher velocities introduce instability to the algorithm, manifesting as noise in the <code>Average Cost</code> plot. Notably, a <code>MaxVel</code> of 0.01 resulted in an <code>Average Cost</code> oscillating around 18, while reducing <code>MaxVel</code> to 0.001 led to oscillations closer to 16. This velocity variation also impacted the Best Cost of the particles; higher velocities correlated with higher <code>Best Cost</code>. This sensitivity of the algorithm to velocity proves crucial when tackling the bin packing problem.</p><p>In addition to velocity, the parameters related to inertia, <code>w</code> and <code>wdamp</code>, and learning factors , <code>c1</code> and <code>c2</code> underwent testing. To comprehend their impacts better, mutations were maintained at lower values. If set too low, the algorithm would require more iterations to find the optimal solution due to excessively low velocities, thereby affecting simulation time. Conversely, excessively high values would cause velocities to saturate quickly to the maximum allowed value, which is also suboptimal. However, unlike mutations, these parameters didn&rsquo;t exhibit the same influential impact. Ultimately, values were selected based on recommendations found in literature, settling on <code>c1 = c2 = 2</code>, <code>w = 0.9</code> and <code>wdamp = 0.99</code>.</p><p>Afterwards, the PSO algorithm underwent testing utilizing the following parameters: <code>nPop = 10</code>, <code>w = 0.9</code>, <code>wdamp = 0.99</code>, <code>c1 = c2 = 2</code>, <code>VelMax = 0.0001</code>, <code>nParticleMutation = 3</code> and <code>nGlobalBestMutation = 20</code>:</p><p><img src=https://live.staticflickr.com/65535/53359214432_4fd4ff5172.jpg alt=123></p><p>Next, convergence for best cost (left) and average cost (right) over the iterations was depicted:</p><p><img src=https://live.staticflickr.com/65535/53360310203_29792b6c15_b.jpg alt=1241f></p><p>In this simulation, the PSO algorithm completed 206 iterations within 2.52 seconds before reaching its stopping criteria. Remarkably, it displayed rapid convergence for this specific benchmark. The average cost of the particles notably decreased to 15.8 before the simulation concluded. Typically, this value fluctuates between 15 and 16 with a higher number of iterations.</p><h3 id=32-second-benchmark>3.2. Second Benchmark
<a class=anchor href=#32-second-benchmark>#</a></h3><p>In the second benchmark, the PSO underwent testing using identical parameters to those employed in the first benchmark: <code>nPop = 10</code>, <code>w = 0.9</code>, <code>wdamp = 0.99</code>, <code>c1 = c2 = 2</code>, <code>VelMax = 0.0001</code>, <code>nParticleMutation = 3</code> and <code>nGlobalBestMutation = 20</code>.</p><p>While the algorithm doesn&rsquo;t yield identical results in each simulation, it managed to attain the optimal solution in certain instances. Here is the outcome of one such simulation depicted:</p><p><img src=https://live.staticflickr.com/65535/53359214352_f9a2bceea8.jpg alt=asfvcc2></p><p><img src=https://live.staticflickr.com/65535/53360419374_79b7e25865_c.jpg alt=asdad></p><p>In this particular simulation, the PSO algorithm required 8895 iterations, spanning 444.18 seconds, before meeting the stopping criteria. The algorithm showcased rapid convergence initially, achieving a cost of less than 101 within 1000 iterations. However, it encountered challenges reaching the optimal solution, nearly getting stuck at certain points, evident in the best cost plot. Throughout the process, the average cost of the particles fluctuated between 105 and 107.</p><h2 id=4-remarks-ga-vs-pso>4 Remarks GA vs. PSO
<a class=anchor href=#4-remarks-ga-vs-pso>#</a></h2><blockquote class="book-hint2 tip"><p class="hint-title tip"><svg class="book-icon"><use href="/svg/hint-icons.svg#tip-notice"/></svg><span>tip</span></p><a href=https://ricardochin.com/docs/code/bin-packing/genetic-algorithm/>Implementation using Genetic Algorithm (GA)</a></blockquote><p>To further test and compare the GA and PSO algorithms, they were ran 10 times each with the second benchmark.</p><p><img src=https://live.staticflickr.com/65535/53359214342_fb24701070_c.jpg alt=sadsad></p><p><img src=https://live.staticflickr.com/65535/53360549430_e11ea23c48_c.jpg alt=das></p><p>In one set of trials, the algorithm achieved 102 bins once and 4 times in total. However, it successfully obtained feasible solutions in 7 out of 10 attempts. The average time across these 10 simulations stood at 284.40 seconds (averaging 6402 iterations). The most efficient solution, involving 101 bins, was attained in 237.06 seconds (5583 iterations).</p><p>Conversely, the PSO algorithm hit the optimal solution only 3 times in 10 simulations, which is less than ideal. Nonetheless, it managed to secure feasible solutions in 9 out of these 10 instances. Notably, the algorithm failed to obtain a feasible solution only when attempting to accommodate all items within 99 bins—an impossible feat. The average time for these 10 simulations totaled 149.37 seconds (averaging 3160 iterations). The best time among the 3 optimal solutions was 107.84 seconds (2303 iterations). Interestingly, three out of the first five simulations resulted in optimal solutions.</p><p>Comparatively, both algorithms encountered a higher percentage of non-feasible solutions in the second benchmark compared to the first. This discrepancy aligns with expectations, given the increased complexity of the second benchmark.</p><h2 id=5-ending-thoughts>5 Ending Thoughts
<a class=anchor href=#5-ending-thoughts>#</a></h2><p><a href=https://ricardochin.com/docs/code/bin-packing/#5-ending-thoughts>Brief summary about the algorithms in the main chapter.</a></p></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/roaked/roaked.github.io/commit/556f08c16dd6734004ba790e5dd30e60447f49a0 title='Last modified by roaked | February 16, 2024' target=_blank rel=noopener><img src=/svg/calendar.svg class=book-icon alt=Calendar>
<span>February 16, 2024</span></a></div><div><a class="flex align-center" href=https://github.com/roaked/roaked.github.io/edit/main/content/content/docs/code/bin-packing/particle-swarm-optimization.md target=_blank rel=noopener><img src=/svg/edit.svg class=book-icon alt=Edit>
<span>Ricardo Chin</span></a></div></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#1-algorithm-concept>1 Algorithm Concept</a></li><li><a href=#2-code-implementation>2 Code Implementation</a></li><li><a href=#3-results>3 Results</a><ul><li><a href=#31-first-benchmark>3.1. First Benchmark</a></li><li><a href=#32-second-benchmark>3.2. Second Benchmark</a></li></ul></li><li><a href=#4-remarks-ga-vs-pso>4 Remarks GA vs. PSO</a></li><li><a href=#5-ending-thoughts>5 Ending Thoughts</a></li></ul></nav></div></aside></main></body></html>