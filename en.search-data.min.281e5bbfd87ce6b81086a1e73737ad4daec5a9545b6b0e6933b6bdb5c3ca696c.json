[{"id":0,"href":"/docs/1design/","title":"Design Portfolio","section":"Docs","content":" Workflow # Hey there! Welcome to my project portfolioâ€”an exciting showcase collected from my academic journey and collaborative endeavours. Within these digital pages, you\u0026rsquo;ll immerse yourself in an environment driven by Computational Fluid Dynamics (CFD) and Finite Element Analysis (FEA), coupled with a plethora of 3D CAD project designs. From conceptualization to execution, these projects were born from late-night brainstorming sessions, leveraging cutting-edge tools to simulate fluid dynamics and structural mechanics, and to bring innovative 3D concepts to life \u0026ndash; Exploring the thrilling realm where design meets simulation!\nI am always open to collaborate in any design projects!\n"},{"id":1,"href":"/docs/3research/1ebeam/","title":"Electron Beam Welding","section":"Research","content":" Thermally Induced Reduction of Hot Cracking Susceptibility # In this following list, I showcase some of the projects I developped either through findings during my academic journey or some extracurricular projects with a few of my fellow friends. Hope you enjoy!\n#1 Master # "},{"id":2,"href":"/docs/1design/4mcomp/","title":"Finite Element Model Formulation","section":"Design Portfolio","content":" 1. Mathematical Background # 1.1 Partial Differential Equations (PDEs) # In engineering and physics, problems are often described by partial differential equations (PDEs). The \u0026ldquo;strong form\u0026rdquo; refers to the original differential equation that must hold exactly throughout the domain, including both the governing equation and the boundary conditions.\nHowever, there are cases where directly solving the strong form might be challenging due to complexities in the equation, irregular geometries, or varying boundary conditions. This is where the \u0026ldquo;weak formulation\u0026rdquo; or (\u0026ldquo;weak form\u0026rdquo;) becomes advantageous.\nThe weak form introduces a relaxation of the constraints imposed by the strong form by multiplying the governing equation with a weight function (typically a test function) and integrating it over the domain. This relaxation allows for more flexibility in solution techniques and offers several advantages:\nHandling Boundary Conditions: The weak form often simplifies the imposition of different types of boundary conditions.\nSolvability: Some differential equations in the strong form might not have exact solutions or might be difficult to solve directly. The weak form can lead to a more manageable equation for numerical methods.\nAdaptability to Numerical Methods: Finite element, boundary element, and other numerical methods are often more easily applied to weak formulations due to the integral nature of the equations.\nHandling Discontinuities: In problems involving discontinuities or singularities, the weak form can handle these cases more effectively.\nMinimization of Requirements: In some cases, the requirement for differentiability or the number of times an equation needs to be differentiated is reduced, easing computational complexity.\nOverall, the weak form is favoured in many situations because it relaxes the strictness of the original problem while maintaining the essential properties required for solutions, making it more adaptable for various solution techniques, especially in numerical analysis.\n1.2 Strong Form # Let\u0026rsquo;s begin by establishing the strong formulation of the problem, which serves as the foundation of our problem. In this formulation, we encapsulate the fundamental differential equation governing the system\u0026rsquo;s behaviour. This equation, along with the precise boundary conditions and initial values, constitutes the direct representation of the underlying physical laws guiding the system\u0026rsquo;s dynamics.\n\\[\\theta - \\nabla \\cdot (k \\nabla u) = f\\] For the torsional loading problem k = 1 and f = 2. The following equations indulge:\n\\[\\frac{\\partial^2 \\phi}{\\partial x^2} \u0026#43; \\frac{\\partial^2 \\phi}{\\partial y^2} = - 2G \\theta\\] This is referring to the Prandtl stress function, which defines shear stresses as:\n\\[\\tau_{xz} = \\frac{\\partial \\phi}{\\partial y} \\text{ and } \\tau_{yz} = \\frac{\\partial \\phi}{\\partial x}\\] The resolution of a torsion problem involves solving the Prandtl equation by imposing the boundary condition around the entire perimeter of the figure, as is known:\n\\[\\phi = 0\\] To do this, the Prandtl function is divided by \\(G\\theta\\) , considering this value is not known, as follows in the next set of expressions:\n\\[\\frac{\\partial^2 \\psi}{\\partial x^2} \u0026#43; \\frac{\\partial^2 \\psi}{\\partial y^2} = - 2 \\text{ and } \\psi = \\frac{\\phi}{G \\theta}\\] \\[\\tau_{yz} = -G \\theta \\frac{\\partial \\psi}{\\partial x} \\text{ and } \\tau_{xz} = G \\theta \\frac{\\partial \\psi}{\\partial y}\\] The developed program will calculate the solution given by \\(\\psi\\) for each node, the shear stresses, and the value of torsional rigidity. The problem of \\(G \\theta\\) is solved using the formula:\n\\[G \\theta = \\frac{Mt}{J}\\] In the previous formula, the M (torsional moment) and t (thickness) take the value of 1.\n1.3 Weak Form # The weak form enables transforming the differential equation into an integral equation, where the initial approach involves integrating the equation across the entire domain. Rules are applied to obtain the weak form, namely, defining the residual by multiplying it with an arbitrary function, integrating by parts the highest-order term, and rearranging the equation. Thus:\n\\[\\iint_S \\frac{\\partial \\phi_i}{\\partial x} \\frac{\\partial \\phi_j}{\\partial x} \u0026#43; \\frac{\\partial \\phi_i}{\\partial y} \\frac{\\partial \\phi_j}{\\partial y} dA = \\iint_S 2\\phi_i dA\\] The stiffnex matrix is given by:\n\\[K_{ij} = \\iint_S \\frac{\\partial \\phi_i}{\\partial x} \\frac{\\partial \\phi_j}{\\partial x} \u0026#43; \\frac{\\partial \\phi_i}{\\partial y} \\frac{\\partial \\phi_j}{\\partial y} dx dy\\] Additionally, the load vector is presented as:\n\\[F_i = \\iint_S 2 \\phi_i dx dy\\] In the considered problem, the only essential boundary condition will be the null solution across the entire perimeter of the figure, accompanied by a distributed load of magnitude 2 applied across the entire mesh.\n1.4 Analytical Integration # Simplifying the problem\u0026rsquo;s resolution, only regular 4-node elements with 1 degree of freedom will be considered. Information from the book \u0026ldquo;Introduction to the Finite Element Method (3rd edition)\u0026rdquo; by J.N. Reddy provides the following details:\nStiffness matrix (e): \\(K^e = \\frac{k}{6ab} \\begin{bmatrix} 2(a^2\u0026#43;b^2) \u0026amp; a^2-2b^2 \u0026amp; -(a^2\u0026#43;b^2) \u0026amp; -2a^2\u0026#43;b^2\\\\ a^2-2b^2 \u0026amp; 2(a^2\u0026#43;b^2) \u0026amp; -2a^2\u0026#43;b^2 \u0026amp; -(a^2\u0026#43;b^2)\\\\ -(a^2\u0026#43;b^2) \u0026amp; -2a^2\u0026#43;b^2 \u0026amp; 2(a^2\u0026#43;b^2) \u0026amp; a^2-2b^2\\\\ -2a^2\u0026#43;b^2 \u0026amp; -(a^2\u0026#43;b^2) \u0026amp; a^2-2b^2 \u0026amp; 2(a^2\u0026#43;b^2)\\\\ \\end{bmatrix} \\) Load vector (e): \\(f^e =\\frac{fab}{4} \\begin{bmatrix} 1\\\\ 1\\\\ 1\\\\ 1\\\\ \\end{bmatrix} \\) Where \u0026lsquo;a\u0026rsquo; corresponds to the length of the base of the element, and \u0026lsquo;b\u0026rsquo; corresponds to the height of the element.\n1.5 Numerical Integration # These functions aim to calculate the elemental stiffness matrix using the Gauss-Jordan approximation, which simplifies integration to a summation. To achieve this, a coordinate transformation from \\((x,y)\\) to \\( (\\xi, \\eta) \\) is applied, while also computing the Jacobian of this transformation. Subsequently, the rules of Gauss points are employed.\nIn Gauss integration, the stiffness matrix K is computed through reduced integrals:\n\\[K_{ij} = \\frac{\\partial \\phi_i}{\\partial x} \\frac{\\partial \\phi_j}{\\partial x} \u0026#43; \\frac{\\partial \\phi_i}{\\partial y} \\frac{\\partial \\phi_j}{\\partial y} \\times J \\times w\\] \\[J = \\begin{bmatrix} \\frac{\\partial x}{\\partial \\xi} \u0026amp; \\frac{\\partial x}{\\partial \\eta}\\\\ \\frac{\\partial y}{\\partial \\xi} \u0026amp; \\frac{\\partial y}{\\partial \\eta}\\\\ \\end{bmatrix} = \\frac{ab}{4}\\] In the previous Gauss integration, \u0026lsquo;w\u0026rsquo; corresponds to the integration weights. For a 1x1 integration, the integration is performed solely at the center of the element, with a weight of w = 1. For 2x1 or 1x2 integration, each \u0026lsquo;w\u0026rsquo; value represents the sum of 2 reduced integrals (2 different points within the element), and the weight is w=2. For a 2x2 integration, the summation includes 4 reduced integrals (4 different points), and w=1. The following values of \\(\\overline{x}\\) and \\(\\overline{y}\\) correspond to the Gauss points:\n\\[\\phi_1 = (1-\\frac{\\overline{y}}{b})(1-\\frac{\\overline{x}}{a}) \\quad \\quad \\phi_2 = \\frac{\\overline{x}}{a}(1-\\frac{\\overline{y}}{b})\\] \\[\\phi_3 = \\frac{\\overline{y}}{b}\\frac{\\overline{x}}{a} \\quad \\quad \\phi_4 = \\frac{\\overline{y}}{b}(1-\\frac{\\overline{x}}{a})\\] Consequently:\n\\[ \\text{1x1 Rule} : \\overline{x}=\\frac{a}{2} \\quad \\text{and} \\quad \\overline{y}=\\frac{b}{2}\\] \\[ \\text{2x2 Rule} : \\overline{x_{1,2}}=\\frac{a}{2}(1 \\pm \\sqrt{\\frac{1}{3}}) \\quad \\text{and} \\quad \\overline{y_{1,2}}=\\frac{b}{2}(1 \\pm \\sqrt{\\frac{1}{3}})\\] 1.6 Torsional Constant # After calculating the nodal solution, the torsion constant J can be determined by:\n\\[J^e = \\int_0^b \\int_0^a 2 \\psi^e dxdy = \\frac{ab}{2}(\\psi_1 \u0026#43; \\psi_2 \u0026#43; \\psi_3 \u0026#43; \\psi_4) \\qquad J = \\sum_i J_i^e\\] 1.7 Shear Stresses # \\[\\tau_{yz} = -G \\theta \\frac{\\partial \\psi}{\\partial x} = -G \\theta (\\frac{\\partial \\phi_1}{\\partial \\overline{x}}\\psi_1 \u0026#43; \\frac{\\partial \\phi_2}{\\partial \\overline{x}}\\psi_2 \u0026#43; \\frac{\\partial \\phi_3}{\\partial \\overline{x}}\\psi_3 \u0026#43; \\frac{\\partial \\phi_4}{\\partial \\overline{x}}\\psi_4)\\] \\[\\tau_{xz} = G \\theta \\frac{\\partial \\psi}{\\partial y} = G \\theta (\\frac{\\partial \\phi_1}{\\partial \\overline{y}}\\psi_1 \u0026#43; \\frac{\\partial \\phi_2}{\\partial \\overline{y}}\\psi_2 \u0026#43; \\frac{\\partial \\phi_3}{\\partial \\overline{y}}\\psi_3 \u0026#43; \\frac{\\partial \\phi_4}{\\partial \\overline{y}}\\psi_4)\\] \\[\\tau_{xy} = \\sqrt{\\tau_{yz}^2 \u0026#43;\\tau_{xz}^2}\\] 2 Time for some coding! # 2.1 READ_ME # The program starts by executing the script \u0026ldquo;MainG10.m\u0026rdquo; directly available on my github page and should contain all the subfunctions and their respective \u0026rsquo;txt\u0026rsquo; files in the respective folder. Once the program is initiated, the user inputs the data file name in the form of \u0026ldquo;nome.txt.\u0026rdquo; The data file should contain the node coordinates, connectivity matrix, and boundary conditions. The data file created for this problem is named \u0026ldquo;dadosg10.txt\u0026rdquo;.\nAfter submitting the data file, the program reads the file and automatically opens a figure displaying the mesh with numbered nodes and elements. Simultaneously, a menu with various options is displayed. The user should first choose the type of integration and then select the desired plots for shear stresses, stress contour lines, and nodal solutions. Submitting the options is done by entering the corresponding number. The program is terminated by entering the number 0.\nUpon program completion, a file is created containing the data obtained from the last integration performed.\n2.2 Validation Based on Book # The developed program has been tested for a known problem described in the book \u0026ldquo;Introduction to the Finite Element Method (3rd edition)\u0026rdquo; by J.N. Reddy - Example 8.5.6. In this example, torsion of a square section bar was considered. As the problem is axisymmetric, nodal solution and shear stresses were calculated for a quarter of the square. The following results were obtained at the nodes for the nodal solution, using a 4x4 mesh:\n"},{"id":3,"href":"/docs/2code/1drone/","title":"RedBull Drone Racing","section":"Coding Portfolio","content":" Introduction # "},{"id":4,"href":"/docs/1design/1mest/","title":"Structural Mechanics","section":"Design Portfolio","content":" Introduction # Ferre hinnitibus erat accipitrem dixi Troiae tollens # Lorem markdownum, a quoque nutu est quodcumque mandasset veluti. Passim inportuna totidemque nympha fert; repetens pendent, poenarum guttura sed vacet non, mortali undas. Omnis pharetramque gramen portentificisque membris servatum novabis fallit de nubibus atque silvas mihi. Dixit repetitaque Quid; verrit longa; sententia mandat quascumque nescio solebat litore; noctes. Hostem haerentem circuit plenaque tamen.\nPedum ne indigenae finire invergens carpebat Velit posses summoque De fumos illa foret "},{"id":5,"href":"/docs/2code/","title":"Coding Portfolio","section":"Docs","content":" Workflow Summary # In this following list, I showcase some of the projects I developped either through findings during my academic journey or some extracurricular projects with a few of my fellow friends. Hope you enjoy!\n#1 Evolutionary Computation # Lorem markdownum, a quoque nutu est quodcumque mandasset veluti. Passim inportuna totidemque nympha fert; repetens pendent, poenarum guttura sed vacet non, mortali undas. Omnis pharetramque gramen portentificisque membris servatum novabis fallit de nubibus atque silvas mihi. Dixit repetitaque Quid; verrit longa; sententia mandat quascumque nescio solebat litore; noctes. Hostem haerentem circuit plenaque tamen.\nPedum ne indigenae finire invergens carpebat Velit posses summoque De fumos illa foret "},{"id":6,"href":"/docs/1design/2thermo/","title":"ThermoCup","section":"Design Portfolio","content":" ThermoCup # 1.1 What is the ThermoCup? # ThermoCup is a unique competition introduced initially at the Technical University of Lisbon during the MecanIST conferences in early 2016. Its primary objective is to challenge participants to conceive, design, and construct a steam boat. The competition covers a comprehensive spectrum of engineering aspects, incorporating various stages of the project lifecycle, from the initial conceptualization and design phase to the practical implementation, prototyping, and subsequent optimization processes.\n1.2 Transversal Disciplines # The challenges within ThermoCup likely encompass a range of engineering disciplines, including:\nMechanical Engineering: To design the physical structure of the steam boat, accounting for structural integrity and efficiency.\nThermal Engineering: Understanding and optimizing the heat transfer mechanisms involved in generating steam to power the boat.\nFluid Dynamics: Analyzing the flow of steam and water within the boat\u0026rsquo;s components to maximize propulsion and efficiency.\nComputational Modeling: Employing Ansys Fluent workbench for virtual simulations to predict and optimize the boat\u0026rsquo;s performance before physical construction.\n1.3 Initial Considerations # In the context of designing a steam boat for ThermoCup, the significance of defining boundary conditions and material selection cannot be overstated. These initial steps essentially set the groundwork for the entire project, exerting a profound influence on the boat\u0026rsquo;s performance and its eventual success in the competition.\nBoundary Conditions: Determining the environmental constraints, operational parameters, and physical limitations within which the steam boat will be mainly vital to perform CFD simulations. This includes factors such as the type of water body the boat will navigate, assumption of variations in temperature and pressure, and even limitations on the size and weight of the boat. In this case, it was intended to be an indoors competition - involving not so high velocities. Hence, mostly laminar flow, therefore a lot of simplifications were conducted to get a rough estimation of how each parameter would impact our results. However, accurately defining these boundary conditions allows participants to tailor their designs to suit real-world scenarios, ensuring the boat\u0026rsquo;s functionality under specific circumstances.\nMaterial Selection: The choice of materials for constructing the steam boat significantly impacts its structural integrity, weight, buoyancy, and overall performance. For instance, selecting lightweight yet durable materials for the boat\u0026rsquo;s structure can enhance its maneuverability and efficiency. Similarly, heat-resistant materials might be crucial for components exposed to high temperatures in the steam propulsion system.\nBut\u0026hellip;\nKeep in mind that the competition\u0026rsquo;s rules imposed caused certain constraints or guidelines regarding the materials that can be used, limitating creativity work to develop within those boundaries.\n1.4 Computational Fluid Dynamics # The utilization of Computational Fluid Dynamics (CFD) simulations with Ansys Fluent workbench within the ThermoCup competition marked a significant and intriguing facet of the event. Ansys Fluent is a robust software suite widely employed in engineering disciplines to simulate and analyze fluid flow, heat transfer, and associated phenomena in intricate detail.\nIn the context of ThermoCup, the incorporation of Ansys Fluent implied a multifaceted challenge for everyone beyond merely constructing a physical steam boat! It introduced a dimension where participants leverage advanced virtual simulations to iteratively refine their designs and optimize the performance of their boats via:\nVirtual Prototyping Performance Optimization Predictive Analysis Surely using machine learning tools this could have been more efficient, but for that moment it yielded good results!\n1.5 Our Solution # Attempts 1 Attempts 2 Attempts ALL After countless combinations of material and design, the choice of cork as the structural material for the steam boat in the ThermoCup competition seemed to have been a well-considered decision. Cork is known for its buoyant and lightweight properties (refer to previous Ch.2), and its higher density compared to materials like polystyrene likely provided the necessary weight and structural stability for the boat. This was especially important when simulating the boat\u0026rsquo;s performance under the natural conditions of flow, which can be challenging at higher speeds due to introduced turbulence flow and higher hydrodynamic forces, including drag and lift that can lead to steer off course as it interacts with the surrounding water.\n1.6 Outlook # \\[v_{\\text{km/h}} = \\frac{8}{18.9} \\times 3.6 \\approx 1.53\\text{ km/h}\\] Securing 3rd place in the competition, covering an 8-meter water lane in just 18.9 seconds, while achieving a average speed of 1.53 km/h, is a notable result. While it is not perfect, it compromised diverse engineering problem-solving skills between meticulous material selection and thoughtful design considerations by the team.\n"},{"id":7,"href":"/docs/1design/3pmec/","title":"Mechanical Project Design","section":"Design Portfolio","content":" Introduction # Ferre hinnitibus erat accipitrem dixi Troiae tollens # Lorem markdownum, a quoque nutu est quodcumque mandasset veluti. Passim inportuna totidemque nympha fert; repetens pendent, poenarum guttura sed vacet non, mortali undas. Omnis pharetramque gramen portentificisque membris servatum novabis fallit de nubibus atque silvas mihi. Dixit repetitaque Quid; verrit longa; sententia mandat quascumque nescio solebat litore; noctes. Hostem haerentem circuit plenaque tamen.\nPedum ne indigenae finire invergens carpebat Velit posses summoque De fumos illa foret "},{"id":8,"href":"/docs/2code/3sint/","title":"Predicting Fake News with ML","section":"Coding Portfolio","content":" Language Characteristics for Detection of Fake News # 1.1 A Growing Case # Fake news, a term emblematic of fabricated information intentionally disseminated across traditional news outlets or online social platforms, embodies deliberate disinformation strategies. These falsehoods aim to tarnish individuals, entities, or gain financial or political advantages, often employing misleading, attention-grabbing headlines. Some counterfeit news pieces disguise themselves as satirical content, sounding incredulous to the point of absurdity, yet managing to deceive unsuspecting audiences.\nThe proliferation of digital media and social networks has led to a rampant increase in fake news dissemination, presenting a contemporary societal challenge. Misinformation, with its potential to adversely impact lives, demands the crucial ability to differentiate between genuine and counterfeit news. This task is intricate; genuine news might appear implausible to the average reader, while fake news endeavours to appear credible.\nAddressing this contemporary issue involves the automatic identification and prevention of fake news dissemination. Efforts by digital corporations and journalistic agencies have attempted to combat fake news, but these solutions have shown imperfections. Academic research has delved into understanding the propagation of fake news, recognizing language usage as a vital parameter in these investigations.\nStudies such as those by Mahyoob in his paper titled Linguistic-Based Detection of Fake News in Social Media and by Preston Detecting fake news on Facebook: The role of emotional intelligence shed light on the analysis of language characteristics in detecting fake news, providing insights, particularly for this application within the context of Portuguese news.\nAdditionally, reports by Facebook and FactCheck.org detail the challenges and strategies in combatting misinformation, emphasizing the significance of linguistic analysis in verifying news authenticity.\nIn this project, drawing upon a meticulously curated corpus comprising 3600 true and 3600 fake Portuguese news samples, collected from January 2016 to January 2018, I aimed to automatically identify fake news using aforementioned language characteristics. This endeavour relied on analyzing 21 specific language traits meticulously classified by the corpus\u0026rsquo; authors to transform news articles into metadata, aligning with methodologies outlined by academic works and industry efforts in the field.\nThe goal of this project is to utilize established machine learning techniques, as previously outlined in research by Mahyoob and Preston, employing each language characteristic as a metadata feature, to effectively identify and mitigate the spread of fake news within Portuguese-language news sources.\n1.2 Approach Brainstorming # Following the problem description, there are 21 features to be analyzed:\nFeatures (click to expand) Number Feature 1 number of tokens 2 number of words without punctuation 3 number of types 4 number of links inside the news 5 number of words in upper case 6 number of verbs 7 number of subjunctive and imperative verbs 8 number of nouns 9 number of adjectives 10 number of adverbs 11 number of modal verbs (mainly auxiliary verbs) 12 number of singular first and second personal pronouns 13 number of plural first personal pronouns 14 number of pronouns 15 pausality 16 number of characters 17 average sentence length 18 average word length 19 percentage of news with spelling errors 20 emotiveness 21 diversity The initial step towards obtaining meaningful results involves preprocessing the available data. Determining which features to utilize for further division into training and testing sets was a crucial decision point, expounded upon in the following section. How were these features selected?\nA thorough study was conducted employing statistical methods to assess the variability within each feature\u0026rsquo;s dataset. Features demonstrating minimal variation, essentially stagnant in their values, were deemed non-contributory and subsequently excluded. Once these less informative features were removed, attention shifted to observing how these features varied between fake and true news samples. Four specific linguistic features were ultimately chosen, drawing from both statistical analysis and intuitive considerations.\nTwo distinct datasets were created: one encompassing all 21 features and another featuring only the selected linguistic features. Throughout the project, these sets were compared, and the resultant differences were discussed. It was anticipated that utilizing a mere four features, compared to the full 21, might yield inferior outcomes due to the reduced dataset facilitating the differentiation between fake and genuine news.\nConsideration for computational resources remained pivotal. The project emphasized optimizing computational efficiency, recognizing that certain models, such as clustering or neural networks, could demand substantial computation power. Maintaining a balance between model complexity and computational demand was crucial. Efficiency was prioritized without compromising noticeable accuracy outcomes.\nFinally, acknowledging the variance in model results across simulations and the potential for parameter customization, efforts focused on identifying optimal parameter values for maximizing accuracy within each model. This iterative approach aimed to fine-tune model parameters for improved performance, considering the inherent variability in results across different simulations.\n1.3 Data Preprocessing # The dataset utilized in this project originated from the \u0026ldquo;Fake.Br Corpus\u0026rdquo; directly available at Roney Santos\u0026rsquo; github page specifically curated to encompass both true and false news in Brazilian Portuguese.\nThis corpus originally contained complete news articles. However, the focus narrowed down to extract the essential features embedded within each news piece. All data was initially formatted in .txt files, necessitating the development of a MATLAB script to convert it into a more manageable .mat format.\n# Preprocessing data # N = number of news N = 1:3602 # Remove news that for some reason don\u0026#39;t exist N(697) = [] N(1467) = [] for i in N: # metaInputs will be the input for the models # importfile opens the txt files and saves them as mat variables # metaInputsTrue[:,i] = importfile(sprintf(\u0026#39;%d-meta.txt\u0026#39;,i)) metaInputsFake[:,i] = importfile(sprintf(\u0026#39;%d-meta.txt\u0026#39;,i)) # metaTargets will be the targets of the neural network # metaTargetsTrue[:,i] = [1, 0] metaTargetsFake[:,i] = [0, 1] metaInputs = [metaInputsTrue metaInputsFake] metaTargets = [metaTargetsTrue metaTargetsFake] As it is seen, this transformation yielded two primary files: \u0026lsquo;metaInputs.mat,\u0026rsquo; housing parameters for all news articles, and \u0026lsquo;metaTargets.mat,\u0026rsquo; distinguishing true news (indicated by a \u0026lsquo;1\u0026rsquo; in the first row) from false news (marked with a \u0026lsquo;0\u0026rsquo; in the second row). To simplify navigation, a structural layout was adopted: the first half of the parameter files consistently represented true news, while the subsequent half constituted false news. This deliberate arrangement facilitated easier comprehension through the interpretation of variables and generated plots.\nThe dataset underwent a division into training and validation subsets. Employing a random selection method, 75% of the dataset was allocated for model training, while the remaining 25% served as a validation set.\nAnalyzing the pivotal features responsible for differentiating between authentic and deceptive news involved employing various statistical methods such as \u0026lsquo;corrplot,\u0026rsquo; \u0026lsquo;matrixplot,\u0026rsquo; and \u0026lsquo;boxplot\u0026rsquo;. However, the outcomes indicated that many features exhibited high non-linearity, posing a challenge in extracting meaningful correlations and insights.\nThe only meaningful contribution came from the Boxplot.py Python function given its concise visualization using key statistics like the minimum, quartiles, median, and maximum values, providing insights into data distribution. It efficiently identifies outliers, assesses symmetry, measures data clustering, and detects potential skewness in the dataset.\n1.4 Methodology # Previously, all methods were initially applied to the entire set of features, followed by a re-execution using only the linguistic features for comparison. This approach aimed to gauge the potential trade-off between accuracy and computational efficiency, as eliminating numerous features could expedite processing time. Moreover, the objective shifted from merely identifying blatantly obvious fake news (e.g., those with poor punctuation or grammar) to developing a model adept at detecting less instances of misinformation, as indicated by the selected linguistic features.\n1.4.1 Clustering # The clustering classification method involves creating distinct clusters based on the available features and assigning each cluster a class label, distinguishing between true and fake news.\nTwo types of clustering techniques, fuzzy c-means and k-means clustering, were employed. Crisp clustering algorithms allocate each data point to a single cluster based on quantified similarity, while fuzzy clustering allows varying degrees of membership to multiple clusters, reflecting diverse similarities.\nDetermining the optimal number of clusters was an initial consideration. Initially, there was a belief that higher cluster counts might yield better results, supported by a MATLAB function \u0026rsquo;evalclusters\u0026rsquo;. However, a comprehensive study later revealed this wasn\u0026rsquo;t always the case.\nCommencing with K-Means clustering, an algorithm using centroids and distance metrics, data points are associated with the nearest centroid, often calculated using squared Euclidean distances.\nK-means clustering partitions observations into sets to minimize the within-cluster sum of squares. The objective function minimizes the variance by grouping observations into clusters.\n\\[\\text{Cost Function} = \\text{argmin}_S k \\sum_{i=1}^{k} \\sum_{x \\in S_i} \\| x - \\mu_i \\|_2^2 = \\text{argmin}_S k \\sum_{i=1}^{k} |S_i| \\text{Var}(S_i)\\] Variables Description for K-means clustering (click to expand) S denotes the set of clusters. k represents the number of clusters. x is a data point. \\mu_i signifies the centroid associated with cluster i. S_i indicates the i^{th} cluster. Var(S_i) represents the variance of cluster i. Identifying clusters containing fake news varied across simulations due to differing cluster numbering. To resolve this, the mode was employed to determine the cluster with the most data points, logically corresponding to fake news, given an equal split between true and fake data points.\nSubsequently, fuzzy c-means clustering was executed, allowing data points to belong to multiple clusters with varying degrees of membership. Parameters such as the initial number of clusters \u0026lsquo;c\u0026rsquo; and the exponent controlling fuzzy overlap \u0026rsquo;m\u0026rsquo; were fine-tuned to optimize accuracy.\nThe FCM algorithm partitions a collection of data into fuzzy clusters, returning cluster centers and a partition matrix indicating each data point\u0026rsquo;s degree of belonging to clusters.\n\\[\\text{Cost Function} = \\text{argmin}_C \\sum_{i=1}^{n} \\sum_{i=1}^{c} w_{ij}^m \\| x_i - c_j \\|_2^2\\] Variables Description for FCM clustering (click to expand) C signifies the collection of clusters. n represents the number of data elements. c denotes the number of fuzzy clusters. x_i represents a data point. c_j signifies the j^{th} cluster center. w_{ij} represents the degree to which x_i belongs to cluster j. m represents the fuzzifier controlling cluster fuzziness. Both FCM and k-means aim to minimize objective functions; however, the addition of membership values and the fuzzifier parameter in FCM allows for fuzzier clustering. The fuzzifier \u0026rsquo;m\u0026rsquo; determines the level of cluster fuzziness, with larger \u0026rsquo;m\u0026rsquo; values resulting in fuzzier clusters, while \u0026rsquo;m=1\u0026rsquo; implies crisp partitioning.\nStudy: Evaluation of exponent \u0026rsquo;m\u0026rsquo; for all features and linguistic features (click to expand) The observed trend indicates that the peak accuracy aligns with the lowest exponent value of \u0026rsquo;m,\u0026rsquo; typically slightly above one unit. Moreover, as the value of \u0026rsquo;m\u0026rsquo; increases, there is an observable exponential decrease in accuracy.\nApplying clustering to linguistic features followed a similar process. The analysis revealed a maximum accuracy of 87.51% concerning the exponent value.\n1.4.2 Fuzzy Modelling # Fuzzy modeling uses rules that are like \u0026ldquo;if-then\u0026rdquo; statements in everyday language. These rules connect input to output in systems that work with vague or uncertain information. There are two main types of rules: one that\u0026rsquo;s easier for people to understand and gives fuzzy (not exact) outputs, and another that\u0026rsquo;s more mathematical, precise, and better for complex systems.\nTo make a fuzzy system, you start by grouping similar data together, allowing for some overlap between the groups. There are different ways to do this grouping. The number of groups usually matches the number of rules used in the system.\nIn these systems, the choice of rules affects how well they work for different tasks. Considering these differences, one type of rule, the Takagi-Sugeno model, was chosen for a specific case because it\u0026rsquo;s better suited for complex systems and provides precise outputs.\nExample: Car\u0026rsquo;s adaptive cruise control system with fuzzy logic - (click to expand) If the distance to the car in front is relatively close and the speed is moderately high, then reduce acceleration slightly. If the distance to the car in front is quite far and the speed is low, then increase acceleration moderately. In this scenario, fuzzy logic allows the system to interpret vague terms like \u0026ldquo;relatively close\u0026rdquo; or \u0026ldquo;quite far\u0026rdquo; regarding the distance to the car ahead. If the system were based on the Takagi-Sugeno model, it would precisely adjust acceleration based on these conditions, ensuring smoother driving and safer distance management. In setting up the fuzzy model, the threshold for the membership function was carefully selected to prioritize minimizing false negatives over false positives. This choice aimed to err on the side of categorizing genuine news as potentially fake rather than labeling false news as true. To pinpoint the most effective threshold value, a dedicated function was designed to identify the optimal point that maximizes the model\u0026rsquo;s accuracy. Across various simulations, this optimal threshold typically fell between 0.45 and 0.55.\nLet\u0026rsquo;s assume an ideal threshold of 0.51: a visual representation illustrates this point. News pieces with a membership value above 0.51 were classified as true (shown above the black lines), while those below were categorized as fake.\nIt was previously mentioned that increasing the number of clusters might not always lead to higher accuracy in Fuzzy Modeling. To confirm this, a study was conducted to explore the relationship between accuracy and the number of clusters.\nStudy: Car\u0026rsquo;s adaptive cruise control system with fuzzy logic - (click to expand) For all features:\nFor linguistic features:\nWhile an increase in clusters appears to enhance the overall consistency of average maximum accuracy, an interesting observation arises. In the simulation involving the highest number of clusters (represented as the last point), the resulting accuracy doesn\u0026rsquo;t perfectly align with the maximum accuracy achieved. Considering that all features were utilized to attain this result, and the accuracy was already quite satisfactory, the differences among the increasing clusters aren\u0026rsquo;t distinctly noticeable.\nFor in-depth study, extracting the membership functions for each features could be done by consulting Fuzzy Modeling and Identification Toolbox fm2tex function\n"},{"id":9,"href":"/docs/3research/","title":"Research","section":"Docs","content":" Workflow Summary # In this following list, I showcase some of the projects I developped either through findings during my academic journey or some extracurricular projects with a few of my fellow friends. Hope you enjoy!\n# "},{"id":10,"href":"/docs/2code/5od/","title":"Evolutionary Computation","section":"Coding Portfolio","content":" Introduction # "},{"id":11,"href":"/docs/1design/1mest/code/","title":"Code","section":"Structural Mechanics","content":" Introduction # Ferre hinnitibus erat accipitrem dixi Troiae tollens # Lorem markdownum, a quoque nutu est quodcumque mandasset veluti. Passim inportuna totidemque nympha fert; repetens pendent, poenarum guttura sed vacet non, mortali undas. Omnis pharetramque gramen portentificisque membris servatum novabis fallit de nubibus atque silvas mihi. Dixit repetitaque Quid; verrit longa; sententia mandat quascumque nescio solebat litore; noctes. Hostem haerentem circuit plenaque tamen.\nPedum ne indigenae finire invergens carpebat Velit posses summoque De fumos illa foret "},{"id":12,"href":"/docs/1design/4mcomp/code/","title":"Code","section":"Finite Element Model Formulation","content":" Introduction # Ferre hinnitibus erat accipitrem dixi Troiae tollens # Lorem markdownum, a quoque nutu est quodcumque mandasset veluti. Passim inportuna totidemque nympha fert; repetens pendent, poenarum guttura sed vacet non, mortali undas. Omnis pharetramque gramen portentificisque membris servatum novabis fallit de nubibus atque silvas mihi. Dixit repetitaque Quid; verrit longa; sententia mandat quascumque nescio solebat litore; noctes. Hostem haerentem circuit plenaque tamen.\nPedum ne indigenae finire invergens carpebat Velit posses summoque De fumos illa foret "}]